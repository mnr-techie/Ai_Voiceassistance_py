# -*- coding: utf-8 -*-
"""AI_VoiceAssisstant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/145pOIwoDknJ69MRHNNfZbfn79GqReSTv

Installation
"""

!pip install -U numpy==1.21
!pip install -q TTS
!pip install -q openai-whisper
!pip install -q gradio
!pip install -q openai
!pip install -q Ipython

import whisper
import gradio as gr
import openai
from TTS.api import TTS

tts_instance = TTS("speaker_model", gpu=True)
tts_instance.list_models()

model_name = TTS.list_models()[9]
tts = TTS(model_name)

tts.tts_to_file(text="This is the A I Project", file_path="output.wav")

from IPython.display import Audio, display
display(Audio('output.wav', autoplay = True))

model = whisper.load_model("medium")

openai.api_key ="secret key" #Use your own api key from open ai

def voice_chat(user_voice):
  messages = [
      {"role":"system","content":"You are kind helpful assistant."},
  ]

  user_message = model.transcribe(user_voice)["text"]

  messages.append(
      {"role":"user","content":user_message},
  )

  print(messages)
  chat = openai.ChatCompletion.create(
      model = "gpt-3.5-turbo",messages = messages
  )

  reply = chat.choices[0].message.content
  messages.append({"role":"assistant","content":reply})
  tts.tts_to_file(text=reply, file_path="output.wav")
  return(reply, 'output.wav')

text_reply = gr.Textbox(label="Text Result")
voice_reply = gr.Audio('output.wav')

gr.Interface(
    title = 'AI Voice Assistant',
    fn = voice_chat,
    inputs=[
        gr.inputs.Audio(source="microphone",type="filepath")
    ],
    outputs=[
        text_reply, voice_reply

    ],live=True).launch(debug = True)